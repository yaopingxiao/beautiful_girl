{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear  regression\n",
    "import random\n",
    "import numpy as np\n",
    "def inference(w,b,x):\n",
    "    pred_y=w*x+b\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(w,b,x_list,gt_y_list):\n",
    "    avg_loss=0\n",
    "    for i in range(len(x_list)):\n",
    "        avg_loss+=0.5*(w*x_list[i]+b-gt_y_list[i])**2\n",
    "    avg_loss=avg_loss/len(gt_y_list)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(pred_y,gt_y,x):\n",
    "    diff=pred_y-gt_y\n",
    "    dw=diff*x\n",
    "    db=diff\n",
    "    return dw,db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_step_gradient(batch_x_list,batch_y_list,w,b,lr):\n",
    "    avg_dw=0\n",
    "    avg_db=0\n",
    "    batch_size=len(batch_x_list)\n",
    "    for i in range(batch_size):\n",
    "        pred_y=inference(w,b,batch_x_list[i])\n",
    "        dw,db=gradient(pred_y,batch_y_list[i],batch_x_list[i])\n",
    "        avg_dw+=dw\n",
    "        avg_db+=db\n",
    "    avg_dw/=batch_size\n",
    "    avg_db/=batch_size\n",
    "    w-=lr*avg_dw\n",
    "    b-=lr*avg_db\n",
    "    return w,b\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_list,gt_y_list,batch_size,lr,max_iter):\n",
    "    w=0\n",
    "    b=0\n",
    "    num_samples=len(x_list)\n",
    "    for i in range(max_iter):\n",
    "        batch_idxs=np.random.choice(len(x_list),batch_size)\n",
    "        batch_x=[x_list[j] for j in batch_idxs]\n",
    "        batch_y=[x_list[j] for j in batch_idxs]\n",
    "        w,b=cal_step_gradient(batch_x,batch_y,w,b,lr)\n",
    "        print('w:{0},b:{1}'.format(w,b))\n",
    "        print('loss is {0}'.format(eval_loss(w,b,x_list,gt_y_list)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data():\n",
    "    w=random.randint(0,10)+random.random()\n",
    "    b=random.randint(0,5)+random.random()\n",
    "    num_samples=100\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    for i in range(num_samples):\n",
    "        x=random.randint(0,100)+random.random()\n",
    "        y=w * x+ b+ random.random()*random.randint(-1,1)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "    return x_list,y_list,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    x_list,y_list,w,b=get_sample_data()\n",
    "    lr=0.01\n",
    "    max_iter=1000\n",
    "    train(x_list,y_list,50,lr,max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
